{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.lenth</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.lenth</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.lenth  sepal.width  petal.lenth  petal.width  type\n",
       "0          5.1          3.5          1.4          0.2     0\n",
       "1          4.9          3.0          1.4          0.2     0\n",
       "2          4.7          3.2          1.3          0.2     0\n",
       "3          4.6          3.1          1.5          0.2     0\n",
       "4          5.0          3.6          1.4          0.2     0\n",
       "5          5.4          3.9          1.7          0.4     0\n",
       "6          4.6          3.4          1.4          0.3     0\n",
       "7          5.0          3.4          1.5          0.2     0\n",
       "8          4.4          2.9          1.4          0.2     0\n",
       "9          4.9          3.1          1.5          0.1     0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "for the convinience, changing type of flower to ingteger\n",
    "setosa      0\n",
    "versicolor  1 \n",
    "virginica   2\n",
    "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./iris.data\")\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        ''' constructor \n",
    "        feature index : sepal and petal\n",
    "            threshold : best split data of feature\n",
    "                left  : left node\n",
    "                right : node\n",
    "                info_gain = information gain\n",
    "        '''      \n",
    "        # for decision node\n",
    "        self.feature_index = feature_index \n",
    "        self.threshold = threshold\n",
    "        self.left = left \n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        # for leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Class\n",
    "\n",
    "Decision tree is very similar with binary search tree which we have studied at Data structure.\n",
    "So the concept of algorithm is as follows\n",
    "\n",
    "1.Recursive Partitioning\n",
    "Recursive Partitoning is to select a Partitioning point so that the homogeneity of newly created child nodes is maximized by Partitioning.<br>\n",
    "Homogeneity is maximized, which means that impurities are minimized.<br>\n",
    "Impurity can be determined by the Gini coefficient and variance. This algorithm will use the Gini coefficient.<br>\n",
    "\n",
    "2.prunning \n",
    "To prevent overfitting due to too many branches, pruning that combines sub-nodes and parent nodes should be carried out.<br>\n",
    "Overfitting can be prevented by adjusting the maximum depth.<br>\n",
    "\n",
    "max_depth: maximum depth of the tree. If we set it to None, the tree will grow until all the leaves are pure or the hyperparameter min_samples_split has been reached.<br>\n",
    "\n",
    "min_samples_split: indicates the minimum number of observations a sheet must have to continue creating new nodes.<br>\n",
    "\n",
    "min_information_gain: the minimum amount the Information Gain must increase for the tree to continue growing.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        # initialize the root of the tree \n",
    "        \"\"\" \n",
    "                root\n",
    "            nodeL   nodeR    \n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "        \n",
    "        # stopping conditions\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        \n",
    "        ''' \n",
    "        recursive function to build the tree\n",
    "        X : attributes(sepal.lenth to petal.width)  \n",
    "        Y : type (label)\n",
    "        num_samples : row of feature\n",
    "        num_features : column of feature\n",
    "        ''' \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X) #row and colum of features \n",
    "        #print(' sample:',num_samples, ' feature:',num_features,\" Class:\",Y)\n",
    "        # split until stopping conditions are met\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # find the best split\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            #print(\"best split:\",best_split)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "        # compute leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split \n",
    "                  1. take loop and list every feature of index\n",
    "                  2. list every value of features\n",
    "                  3. split dataset according to unique of feature values\n",
    "                  4. dataset value could be null, so if dataset is not null compute impormation gain\n",
    "                  5. information gain is as better as small, if current gain > max gain , change index\n",
    "        '''\n",
    "        \n",
    "        # dictionary to store the best split\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        #print('num_features:',num_features)\n",
    "        # loop over all the features\n",
    "        for feature_index in range(num_features): \n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # loop over all the feature values present in the data\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # compute information gain\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # update the best split if needed\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "                        \n",
    "        # return best split\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        ''' function to split the data \n",
    "            if feature index is smaller than threshold(according to maximum gain), set in left array (node)\n",
    "            if feature index is bigger than threshold, set in right array (node)\n",
    "        '''\n",
    "        \n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        ''' function to compute information gain '''\n",
    "        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        ''' function to compute entropy '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            ratio = len(y[y == cls]) / len(y)\n",
    "            entropy += -ratio * np.log2(ratio)\n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        ''' function to compute gini index '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            ratio = len(y[y == cls]) / len(y)\n",
    "            gini += ratio**2\n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"Feature\"+str(tree.feature_index), \"<=\", tree.threshold, \" Info_Gain:\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ''' function to train the tree '''\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' function to predict new dataset '''\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' function to predict a single data point '''\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (120, 4) , x_test: (30, 4) ,y_train: (120, 1),y_test: (30, 1) \n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "from CHAE_ML import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split.split(X, Y, test_size=0.2,datatype='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature2 <= 1.9  Info_Gain: 0.38690476190476186\n",
      " left:0.0\n",
      " right:Feature2 <= 4.9  Info_Gain: 0.3284742468415938\n",
      "  left:Feature0 <= 4.9  Info_Gain: 0.01957517700957936\n",
      "    left:1.0\n",
      "    right:1.0\n",
      "  right:Feature3 <= 1.7  Info_Gain: 0.10884353741496589\n",
      "    left:1.0\n",
      "    right:2.0\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=2)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./photo/decision_tree_result.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test) \n",
    "#from sklearn.metrics import accuracy_score\n",
    "from CHAE_ML import accuracy\n",
    "accuracy.score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems accuracy score is pretty low. this is because dataset is not splited<br>\n",
    "let's try again with proposal data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "data shuffle complete\n",
      "x_train: (120, 4) , x_test: (30, 4) ,y_train: (120, 1),y_test: (30, 1) \n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "print(type(X))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split.split(X, Y, test_size=0.2,shuffle=True,datatype='ndarray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature2 <= 1.9  Info_Gain: 0.3413247863247863\n",
      " left:0.0\n",
      " right:Feature3 <= 1.7  Info_Gain: 0.3617998810306502\n",
      "  left:Feature2 <= 4.9  Info_Gain: 0.12532328246613972\n",
      "    left:1.0\n",
      "    right:2.0\n",
      "  right:Feature2 <= 4.8  Info_Gain: 0.01697530864197544\n",
      "    left:2.0\n",
      "    right:2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=2)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()\n",
    "\n",
    "Y_pred = classifier.predict(X_test) \n",
    "accuracy.score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the accuracy socre is 96.6% data is classified nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for train test and accuracy\n",
    "\n",
    "class train_test_split:\n",
    "    def __init__(self,data,target,test_size,datatype,shuffle=False):\n",
    "        self._data = data\n",
    "        self._target = target\n",
    "        self._test_size = test_size\n",
    "        self.shuffle = shuffle\n",
    "        self.datatype = datatype\n",
    "        #   self._xtrain = x_train\n",
    "        #   self._xtest = x_test\n",
    "        #   self._ytrain = y_train\n",
    "        #   self._ytest = y_test\n",
    "    @classmethod\n",
    "    def split(self, data ,target ,test_size,shuffle=False,datatype='df'):\n",
    "        #data.reset_index(drop=self.shuffle, inplace=self.shuffle) #데이터를 일단 섞어주기\n",
    "        if(shuffle==True):\n",
    "            if type(data) is np.ndarray:\n",
    "                s = np.arange(data.shape[0])\n",
    "                np.random.shuffle(s)\n",
    "                data=data[s]\n",
    "                target=target[s]\n",
    "                print('data shuffle complete')       \n",
    "            else:#(type(data) is DataFrame and shuffle is True):\n",
    "                s = np.arange(data.value_counts.shape[0])\n",
    "                np.random.shuffle(s)\n",
    "                data=data[s]\n",
    "                target=target[s]\n",
    "                print('data shuffle complete')       \n",
    "\n",
    "\n",
    "        if(datatype== 'df'):\n",
    "            x_train = data.iloc[:round(len(data)*(1-test_size)),:]#0~0.7\n",
    "            y_train = target.iloc[:round(len(target)*(1-test_size)),]\n",
    "            x_test = data.iloc[round(len(data)*(1-test_size)):,:]#0.7~1\n",
    "            y_test = target.iloc[round(len(target)*(1-test_size)):,]#0.7~1\n",
    "        else:\n",
    "            x_train = data[:round(len(data)*(1-test_size)),:]#0~0.7\n",
    "            y_train = target[:round(len(target)*(1-test_size)),]\n",
    "            x_test = data[round(len(data)*(1-test_size)):,:]#0.7~1\n",
    "            y_test = target[round(len(target)*(1-test_size)):,]#0.7~1\n",
    "        # x_train = x_train.to_numpy()\n",
    "        # y_train = y_train.to_numpy()\n",
    "        # x_test = x_test.to_numpy()\n",
    "        # y_test = y_test.to_numpy()\n",
    "        print(\"x_train: {} , x_test: {} ,y_train: {},y_test: {} \".format(x_train.shape, x_test.shape, y_train.shape, y_test.shape))\n",
    "\n",
    "        return x_train , x_test , y_train , y_test \n",
    "\n",
    "\n",
    "class accuracy:\n",
    "    def __init__(self,y_test,y_pred):\n",
    "        self.y_pred = y_test\n",
    "        self.y_data = y_pred\n",
    "    @classmethod\n",
    "    def score(self,y_test,y_pred):\n",
    "        acc=np.mean(y_test==y_pred)\n",
    "        return acc\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08511fb726953861695b9cebc649e5cfa50177e02ef8da1c1316f73897c02d54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
